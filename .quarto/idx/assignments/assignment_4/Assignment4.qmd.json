{"title":"Spatial Predictive Analysis: Chicago Graffiti Removal 311 Requests","markdown":{"yaml":{"title":"Spatial Predictive Analysis: Chicago Graffiti Removal 311 Requests","subtitle":"MUSA 5080 Lab Assignment 4","author":"Yanyang Chen","date":"`r Sys.Date()`","format":{"html":{"toc":true,"toc-depth":3,"code-fold":"show","self-contained":true,"theme":"cosmo","highlight-style":"github"}},"editor":"visual"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(\n  echo = TRUE,\n  warning = FALSE,\n  message = FALSE,\n  fig.width = 14,\n  fig.height = 9,\n  dpi = 300\n)\nset.seed(123)\n```\n\n\nGraffiti represents a persistent challenge to urban neighborhoods, affecting aesthetic quality, public safety perceptions, and property values. Chicago's 311 service request system provides a comprehensive record of graffiti removal requests across the city. This analysis applies spatial predictive modeling to understand whether we can forecast graffiti concentrations using spatial features and count regression models.\n\n**Analysis Goals:** - Develop a spatial predictive model using k-nearest neighbor and Local Moran's I features - Compare Poisson and Negative Binomial regression performance - Validate models using spatial cross-validation (Leave-One-Group-Out) - Test temporal stability using 2018 crime data - Evaluate predictive accuracy against kernel density estimation baseline\n\n------------------------------------------------------------------------\n\n# Part 1: Data Loading and Exploration\n\n## Loading Required Libraries\n\n```{r load_libraries}\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(sf)\nlibrary(sp)\nlibrary(raster)\nlibrary(spdep)\nlibrary(spatstat)\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(viridis)\nlibrary(MASS)\nlibrary(broom)\nlibrary(jsonlite)\nlibrary(httr)\n\ntheme_set(theme_minimal())\n```\n\n## Downloading Graffiti Data from Chicago 311 Portal\n\n```{r load_graffiti_data}\n# Chicago 311 API endpoint for graffiti data\napi_url <- \"https://data.cityofchicago.org/resource/hec5-y4x5.json\"\n\n# Query parameters: download all available data\nparams <- list(\n  \"$limit\" = 50000\n)\n\n# Execute API request\nresponse <- GET(api_url, query = params)\ngraffiti_raw <- fromJSON(content(response, \"text\"))\ngraffiti_df <- as_tibble(graffiti_raw)\n\ncat(\"Raw Graffiti Data Summary:\\n\")\ncat(\"Total Records:\", nrow(graffiti_df), \"\\n\")\ncat(\"Variables:\", ncol(graffiti_df), \"\\n\\n\")\n\n# Check available columns\ncat(\"Available columns:\\n\")\nprint(colnames(graffiti_df))\n```\n\n## Data Cleaning and Preparation\n\n```{r clean_graffiti_data}\n# Clean and prepare graffiti data\ngraffiti_clean <- graffiti_df %>%\n  filter(!is.na(longitude) & !is.na(latitude)) %>%\n  mutate(\n    longitude = as.numeric(longitude),\n    latitude = as.numeric(latitude),\n    creation_date = as.POSIXct(creation_date),\n    year = year(creation_date),\n    month = month(creation_date),\n    date = as_date(creation_date)\n  ) %>%\n  filter(longitude > -88.5 & longitude < -87.5,\n         latitude > 41.6 & latitude < 42.1)\n\ncat(\"Data Cleaning Summary:\\n\")\ncat(\"Records after cleaning: \", nrow(graffiti_clean), \"\\n\")\nif(nrow(graffiti_clean) > 0) {\n  cat(\"Date range: \", min(graffiti_clean$date, na.rm = TRUE), \n      \" to \", max(graffiti_clean$date, na.rm = TRUE), \"\\n\")\n}\n\nhead(graffiti_clean, 5)\n```\n\n## Converting to Spatial Object\n\n```{r convert_to_sf}\n# Convert to sf object (WGS84)\ngraffiti_wgs84 <- st_as_sf(graffiti_clean,\n                            coords = c(\"longitude\", \"latitude\"),\n                            crs = 4326)\n\n# Project to UTM Zone 16N for accurate distance calculations\ngraffiti_utm <- st_transform(graffiti_wgs84, crs = 32616)\n\ncat(\"Spatial Object Created:\\n\")\ncat(\"Total features:\", nrow(graffiti_utm), \"\\n\")\n```\n\n## Loading Chicago City Boundary\n\n```{r load_chicago_boundary}\n# Load Chicago boundary from city's open data portal\nchicago_url <- \"https://data.cityofchicago.org/api/geospatial/igwz-8jzy?method=export&format=GeoJSON\"\nchicago_boundary <- st_read(chicago_url, quiet = TRUE)\n\n# Project to UTM Zone 16N\nchicago_utm <- st_transform(chicago_boundary, crs = 32616)\n\ncat(\"Chicago Boundary Loaded\\n\")\ncat(\"Area:\", round(as.numeric(st_area(chicago_utm))/1e6, 1), \"km²\\n\")\n```\n\n## Visualizing Spatial Distribution\n\n```{r plot_graffiti_points, fig.width=12, fig.height=8}\n# Create base map showing all graffiti points\nggplot() +\n  geom_sf(data = chicago_utm, fill = NA, color = \"black\", linewidth = 0.8) +\n  geom_sf(data = graffiti_utm, color = \"#E31C23\", size = 0.8, alpha = 0.3) +\n  theme_minimal() +\n  labs(\n    title = \"Spatial Distribution of Graffiti Removal Requests\",\n    subtitle = paste(\"Total requests:\", nrow(graffiti_utm)),\n    x = \"UTM Easting (m)\",\n    y = \"UTM Northing (m)\"\n  ) +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 11),\n    axis.text = element_text(size = 9)\n  )\n```\n\n## Temporal Patterns\n\n```{r temporal_analysis, fig.width=12, fig.height=6}\n# Calculate monthly statistics\nmonthly_stats <- graffiti_clean %>%\n  group_by(month) %>%\n  summarise(\n    count = n(),\n    avg_per_day = n() / n_distinct(date),\n    .groups = \"drop\"\n  ) %>%\n  mutate(month_name = month.abb[month])\n\n# Visualize monthly distribution\nggplot(monthly_stats, aes(x = reorder(month_name, month), y = count)) +\n  geom_col(fill = \"#E31C23\", alpha = 0.8, color = \"black\", linewidth = 0.3) +\n  geom_text(aes(label = count), vjust = -0.3, size = 3.5, fontface = \"bold\") +\n  theme_minimal() +\n  labs(\n    title = \"Monthly Distribution of Graffiti Requests\",\n    x = \"Month\",\n    y = \"Number of Requests\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(size = 13, face = \"bold\")\n  )\n\ncat(\"\\nTemporal Summary:\\n\")\nprint(monthly_stats)\n```\n\n------------------------------------------------------------------------\n\n# Part 2: Fishnet Grid Creation\n\n## Creating 500m × 500m Grid\n\n```{r create_fishnet_grid}\n# Create regular grid covering Chicago\nfishnet_full <- st_make_grid(\n  chicago_utm,\n  cellsize = 500,\n  square = TRUE,\n  what = \"polygons\"\n) %>%\n  st_as_sf() %>%\n  mutate(grid_id = row_number())\n\n# Keep only grid cells intersecting Chicago boundary\nfishnet_chicago <- fishnet_full[chicago_utm, ]\n\ncat(\"Fishnet Grid Created:\\n\")\ncat(\"Total grid cells:\", nrow(fishnet_chicago), \"\\n\")\ncat(\"Cell size: 500m × 500m\\n\")\n```\n\n## Aggregating Graffiti Counts to Grid\n\n```{r aggregate_graffiti_to_grid}\n# Aggregate graffiti points to grid cells\ngraffiti_grid <- fishnet_chicago %>%\n  st_join(graffiti_utm, join = st_contains) %>%\n  group_by(grid_id) %>%\n  summarise(\n    n_graffiti = n(),\n    .groups = \"drop\"\n  ) %>%\n  mutate(n_graffiti = ifelse(is.na(n_graffiti), 0, n_graffiti))\n\ncat(\"Grid Aggregation Complete:\\n\")\ncat(\"Total cells:\", nrow(graffiti_grid), \"\\n\")\ncat(\"Cells with graffiti:\", sum(graffiti_grid$n_graffiti > 0), \"\\n\")\ncat(\"Mean per cell:\", round(mean(graffiti_grid$n_graffiti), 2), \"\\n\\n\")\n\nprint(summary(graffiti_grid$n_graffiti))\n```\n\n## Visualizing Grid Aggregation\n\n```{r plot_grid_distribution, fig.width=14, fig.height=8}\n# Map showing graffiti counts per grid cell\np1 <- ggplot() +\n  geom_sf(data = graffiti_grid, aes(fill = n_graffiti), color = NA) +\n  geom_sf(data = chicago_utm, fill = NA, color = \"black\", linewidth = 0.5) +\n  scale_fill_viridis_c(name = \"Requests\", option = \"plasma\") +\n  theme_minimal() +\n  labs(\n    title = \"Graffiti Count Aggregation to 500m Grid\",\n    x = \"UTM Easting (m)\",\n    y = \"UTM Northing (m)\"\n  ) +\n  theme(plot.title = element_text(size = 13, face = \"bold\"))\n\n# Histogram of counts\np2 <- ggplot(graffiti_grid, aes(x = n_graffiti)) +\n  geom_histogram(bins = 40, fill = \"#E31C23\", alpha = 0.8, color = \"black\") +\n  theme_minimal() +\n  labs(\n    title = \"Distribution of Graffiti Counts\",\n    x = \"Requests per Cell\",\n    y = \"Frequency\"\n  ) +\n  theme(plot.title = element_text(size = 12, face = \"bold\"))\n\ngridExtra::grid.arrange(p1, p2, ncol = 2)\n```\n\n------------------------------------------------------------------------\n\n# Part 3: Spatial Features Construction\n\n## Creating Spatial Weights Matrix and Features\n\n```{r spatial_features}\n# Step 1: Ensure graffiti_grid is sf with grid_id\ngraffiti_grid <- graffiti_grid %>%\n  mutate(grid_id = row_number())\n\n# Step 2: Convert to sp object (required by spdep)\ngraffiti_sp <- as_Spatial(graffiti_grid)\n\n# Step 3: Create k-nearest neighbors weight matrix\nknn_neighbors <- knearneigh(coordinates(graffiti_sp), k = 5)\nknn_weights <- knn2nb(knn_neighbors, sym = TRUE)\nknn_weights_std <- nb2listw(knn_weights, style = \"W\")\n\ncat(\"Spatial Weights Matrix Created (k=5 nearest neighbors)\\n\")\n\n# Step 4: Calculate k-NN feature (neighbor mean)\nneighbor_lags <- lag.listw(knn_weights_std, graffiti_grid$n_graffiti)\n\n# Step 5: Calculate Local Moran's I\nlocal_moran <- localmoran(graffiti_grid$n_graffiti, knn_weights_std)\n\n# Step 6: Calculate distance to hotspot\nhotspot_threshold <- quantile(graffiti_grid$n_graffiti, 0.75)\nhotspots <- graffiti_grid %>% filter(n_graffiti >= hotspot_threshold)\nhotspot_center <- st_centroid(st_union(hotspots))\ndist_to_hotspot <- as.numeric(st_distance(graffiti_grid, hotspot_center)) / 1000\n\n# Step 7: Add all features to graffiti_grid\ngraffiti_grid <- graffiti_grid %>%\n  mutate(\n    neighbor_mean = neighbor_lags,\n    local_i = local_moran[, 1],\n    local_i_pval = local_moran[, 5],\n    dist_to_hotspot = dist_to_hotspot,\n    moran_cluster = case_when(\n      local_i_pval >= 0.05 ~ \"Not significant\",\n      local_i >= 0 & n_graffiti >= median(n_graffiti) ~ \"High-High\",\n      local_i >= 0 & n_graffiti < median(n_graffiti) ~ \"Low-Low\",\n      local_i < 0 & n_graffiti >= median(n_graffiti) ~ \"High-Low\",\n      TRUE ~ \"Low-High\"\n    )\n  )\n\ncat(\"\\nSpatial Features Added:\\n\")\ncat(\"neighbor_mean: Average graffiti count in 5 nearest neighbors\\n\")\ncat(\"local_i: Local Moran's I statistic\\n\")\ncat(\"dist_to_hotspot: Distance to graffiti hotspot (km)\\n\")\ncat(\"moran_cluster: Classification of spatial clusters\\n\")\ncat(\"\\nFirst 5 rows:\\n\")\n\nfeature_summary <- graffiti_grid %>% \n  st_drop_geometry()\n\nhead(feature_summary, 5)\n```\n\n## Visualizing Hotspots and Coldspots\n\n```{r plot_local_morans, fig.width=12, fig.height=8}\nggplot() +\n  geom_sf(data = graffiti_grid, aes(fill = moran_cluster), color = NA) +\n  geom_sf(data = chicago_utm, fill = NA, color = \"black\", linewidth = 0.5) +\n  scale_fill_manual(\n    name = \"Cluster Type\",\n    values = c(\n      \"High-High\" = \"#d73027\",\n      \"Low-Low\" = \"#91bfdb\",\n      \"High-Low\" = \"#fee090\",\n      \"Low-High\" = \"#a6d96a\",\n      \"Not significant\" = \"#f7f7f7\"\n    )\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Local Moran's I: Graffiti Hotspots and Coldspots\",\n    x = \"UTM Easting (m)\",\n    y = \"UTM Northing (m)\"\n  ) +\n  theme(plot.title = element_text(size = 13, face = \"bold\"))\n\ncat(\"\\nCluster Distribution:\\n\")\nprint(table(graffiti_grid$moran_cluster))\n```\n\n------------------------------------------------------------------------\n\n# Part 4: Count Regression Models\n\n## Preparing Data for Modeling\n\n```{r model_preparation}\n# Prepare data for modeling\nmodel_data <- graffiti_grid %>%\n  st_drop_geometry() %>%\n  na.omit()\n\ncat(\"Model Data Prepared:\\n\")\ncat(\"Sample size:\", nrow(model_data), \"\\n\")\ncat(\"Dependent variable (n_graffiti):\\n\")\nprint(summary(model_data$n_graffiti))\n\ncat(\"\\nOverdispersion check:\\n\")\ncat(\"Mean:\", mean(model_data$n_graffiti), \"\\n\")\ncat(\"Variance:\", var(model_data$n_graffiti), \"\\n\")\ncat(\"Variance/Mean ratio:\", round(var(model_data$n_graffiti)/mean(model_data$n_graffiti), 2), \"\\n\")\n```\n\n## Poisson Regression\n\n```{r poisson_model}\n# Fit Poisson regression\npoisson_model <- glm(\n  n_graffiti ~ neighbor_mean + local_i + dist_to_hotspot,\n  family = poisson(link = \"log\"),\n  data = model_data\n)\n\ncat(\"POISSON REGRESSION RESULTS\\n\")\ncat(strrep(\"=\", 50), \"\\n\\n\")\nprint(summary(poisson_model))\n\n# Extract metrics\npoisson_aic <- AIC(poisson_model)\npoisson_deviance <- deviance(poisson_model)\npoisson_dispersion <- poisson_deviance / df.residual(poisson_model)\n\ncat(\"\\nModel Fit Statistics:\\n\")\ncat(\"AIC:\", round(poisson_aic, 2), \"\\n\")\ncat(\"Dispersion statistic:\", round(poisson_dispersion, 3), \"\\n\")\n```\n\n## Negative Binomial Regression\n\n```{r negative_binomial_model}\n# Fit Negative Binomial regression\nnb_model <- glm.nb(\n  n_graffiti ~ neighbor_mean + local_i + dist_to_hotspot,\n  data = model_data\n)\n\ncat(\"\\nNEGATIVE BINOMIAL REGRESSION RESULTS\\n\")\ncat(strrep(\"=\", 50), \"\\n\\n\")\nprint(summary(nb_model))\n\n# Extract metrics\nnb_aic <- AIC(nb_model)\nnb_deviance <- deviance(nb_model)\n\ncat(\"\\nModel Fit Statistics:\\n\")\ncat(\"AIC:\", round(nb_aic, 2), \"\\n\")\n```\n\n## Model Comparison\n\n```{r model_comparison}\n# Compare models\ncat(\"\\nMODEL COMPARISON\\n\")\ncat(strrep(\"=\", 50), \"\\n\")\ncat(\"Poisson AIC:\", round(poisson_aic, 2), \"\\n\")\ncat(\"Negative Binomial AIC:\", round(nb_aic, 2), \"\\n\")\ncat(\"Difference:\", round(poisson_aic - nb_aic, 2), \"\\n\\n\")\n\nif (nb_aic < poisson_aic) {\n  cat(\"Decision: Negative Binomial model preferred (lower AIC)\\n\")\n  selected_model <- nb_model\n  model_name <- \"Negative Binomial\"\n} else {\n  cat(\"Decision: Poisson model preferred (lower AIC)\\n\")\n  selected_model <- poisson_model\n  model_name <- \"Poisson\"\n}\n\n# Extract coefficients\ncoef_table <- tidy(selected_model, exponentiate = TRUE, conf.int = TRUE)\n\ncat(\"\\n\\nSelected Model Coefficients (Exponentiated - Incidence Rate Ratios):\\n\")\nprint(coef_table)\n```\n\n------------------------------------------------------------------------\n\n# Part 5: Spatial Cross-Validation\n\n## Setting Up Spatial Folds\n\n```{r spatial_cv_setup}\n# Create spatial folds\nset.seed(123)\nn_folds <- 5\n\ncentroids <- st_coordinates(st_centroid(graffiti_grid))\nspatial_folds <- kmeans(centroids, centers = n_folds)$cluster\n\ncv_data <- model_data %>%\n  mutate(fold = spatial_folds[row_number()])\n\ncat(\"Spatial Cross-Validation Setup:\\n\")\ncat(\"Number of folds:\", n_folds, \"\\n\")\ncat(\"Fold sizes:\\n\")\nprint(table(cv_data$fold))\n```\n\n## Running Cross-Validation\n\n```{r run_spatial_cv}\n# Cross-validation loop\ncv_results <- tibble()\n\nfor (fold_num in 1:n_folds) {\n  train_data <- cv_data %>% filter(fold != fold_num)\n  test_data <- cv_data %>% filter(fold == fold_num)\n  \n  # Fit model on training data\n  if (model_name == \"Negative Binomial\") {\n    fold_model <- glm.nb(\n      n_graffiti ~ neighbor_mean + local_i + dist_to_hotspot,\n      data = train_data\n    )\n  } else {\n    fold_model <- glm(\n      n_graffiti ~ neighbor_mean + local_i + dist_to_hotspot,\n      family = poisson(link = \"log\"),\n      data = train_data\n    )\n  }\n  \n  # Predictions\n  pred <- predict(fold_model, newdata = test_data, type = \"response\")\n  \n  fold_results <- test_data %>%\n    mutate(\n      fold = fold_num,\n      observed = n_graffiti,\n      predicted = pred,\n      error = observed - predicted,\n      abs_error = abs(error),\n      squared_error = error^2\n    )\n  \n  cv_results <- bind_rows(cv_results, fold_results)\n}\n\ncat(\"Cross-Validation Complete:\\n\")\ncat(\"Total predictions:\", nrow(cv_results), \"\\n\")\n```\n\n## Cross-Validation Error Metrics\n\n```{r cv_error_metrics}\n# Calculate error metrics\nmae <- mean(cv_results$abs_error, na.rm = TRUE)\nrmse <- sqrt(mean(cv_results$squared_error, na.rm = TRUE))\nme <- mean(cv_results$error, na.rm = TRUE)\n\ncat(\"SPATIAL CROSS-VALIDATION RESULTS\\n\")\ncat(strrep(\"=\", 50), \"\\n\")\ncat(\"Mean Absolute Error (MAE):\", round(mae, 3), \"\\n\")\ncat(\"Root Mean Squared Error (RMSE):\", round(rmse, 3), \"\\n\")\ncat(\"Mean Error (ME):\", round(me, 3), \"\\n\")\n```\n\n## Visualizing CV Results\n\n```{r plot_cv_results, fig.width=14, fig.height=8}\n# Observed vs Predicted\np1 <- ggplot(cv_results, aes(x = observed, y = predicted)) +\n  geom_point(alpha = 0.5, color = \"#E31C23\") +\n  geom_abline(intercept = 0, slope = 1, color = \"blue\", linetype = \"dashed\") +\n  theme_minimal() +\n  labs(\n    title = \"Spatial CV: Observed vs Predicted\",\n    x = \"Observed\",\n    y = \"Predicted\",\n    subtitle = paste(\"MAE =\", round(mae, 2))\n  ) +\n  theme(plot.title = element_text(size = 12, face = \"bold\"))\n\n# Residuals\np2 <- ggplot(cv_results, aes(x = error)) +\n  geom_histogram(bins = 30, fill = \"#E31C23\", alpha = 0.7) +\n  geom_vline(xintercept = 0, color = \"blue\", linetype = \"dashed\") +\n  theme_minimal() +\n  labs(\n    title = \"Residuals Distribution\",\n    x = \"Prediction Error\",\n    y = \"Frequency\"\n  ) +\n  theme(plot.title = element_text(size = 12, face = \"bold\"))\n\ngridExtra::grid.arrange(p1, p2, ncol = 2)\n```\n\n------------------------------------------------------------------------\n\n# Part 6: Temporal Validation (2018 Data)\n\n## Loading 2018 Crime Data\n\n```{r load_2018_crimes}\n# Download 2018 crimes data\ncrime_url <- \"https://data.cityofchicago.org/resource/3i3m-jwuy.json\"\n\n# Simple query without complex filters\nresponse_2018 <- GET(crime_url, query = list(\"$limit\" = 50000))\ncrime_2018_raw <- fromJSON(content(response_2018, \"text\"))\ncrime_2018_df <- as_tibble(crime_2018_raw)\n\ncat(\"2018 Crime Data Loaded:\\n\")\ncat(\"Total records:\", nrow(crime_2018_df), \"\\n\")\ncat(\"Columns:\", ncol(crime_2018_df), \"\\n\")\n```\n\n## Preparing 2018 Data\n\n```{r prepare_2018_data}\n# Clean 2018 data\ncrime_2018_clean <- crime_2018_df %>%\n  filter(!is.na(longitude) & !is.na(latitude)) %>%\n  mutate(\n    longitude = as.numeric(longitude),\n    latitude = as.numeric(latitude)\n  ) %>%\n  filter(longitude > -88.5 & longitude < -87.5,\n         latitude > 41.6 & latitude < 42.1)\n\n# Convert to sf\ncrime_2018_wgs84 <- st_as_sf(crime_2018_clean,\n                             coords = c(\"longitude\", \"latitude\"),\n                             crs = 4326)\n\ncrime_2018_utm <- st_transform(crime_2018_wgs84, crs = 32616)\n\ncat(\"2018 Data Cleaned:\\n\")\ncat(\"Records:\", nrow(crime_2018_utm), \"\\n\")\n```\n\n## Aggregating 2018 to Same Grid\n\n```{r aggregate_2018_to_grid}\n# Aggregate to grid\ncrime_2018_grid <- fishnet_chicago %>%\n  st_join(crime_2018_utm, join = st_contains) %>%\n  group_by(grid_id) %>%\n  summarise(\n    n_crime = n(),\n    .groups = \"drop\"\n  ) %>%\n  mutate(n_crime = ifelse(is.na(n_crime), 0, n_crime))\n\ncat(\"2018 Aggregation:\\n\")\ncat(\"Total cells:\", nrow(crime_2018_grid), \"\\n\")\ncat(\"Cells with crimes:\", sum(crime_2018_grid$n_crime > 0), \"\\n\")\n```\n\n## Predicting 2018 with 2017 Model\n\n```{r temporal_prediction}\n# Prepare features\ncrime_2018_features <- crime_2018_grid %>%\n  st_drop_geometry() %>%\n  mutate(\n    observed_2018 = n_crime\n  ) %>%\n  left_join(\n    model_data %>% mutate(grid_id = row_number()),\n    by = \"grid_id\"\n  ) %>%\n  na.omit()\n\ncat(\"2018 Features Prepared:\\n\")\ncat(\"Records:\", nrow(crime_2018_features), \"\\n\")\n\n# Make predictions using 2017 model\npred_2018 <- predict(selected_model, \n                     newdata = crime_2018_features, \n                     type = \"response\")\n\ntemporal_results <- crime_2018_features %>%\n  mutate(\n    predicted_2018 = pred_2018,\n    error_2018 = observed_2018 - predicted_2018,\n    abs_error_2018 = abs(error_2018),\n    squared_error_2018 = error_2018^2\n  )\n\ncat(\"Temporal Validation:\\n\")\ncat(\"Predictions made:\", nrow(temporal_results), \"\\n\")\n```\n\n## Temporal Validation Metrics\n\n```{r temporal_error_metrics}\n# Calculate 2018 metrics\nmae_2018 <- mean(temporal_results$abs_error_2018)\nrmse_2018 <- sqrt(mean(temporal_results$squared_error_2018))\n\ncat(\"TEMPORAL VALIDATION (2018)\\n\")\ncat(strrep(\"=\", 50), \"\\n\")\ncat(\"MAE:\", round(mae_2018, 3), \"\\n\")\ncat(\"RMSE:\", round(rmse_2018, 3), \"\\n\")\n```\n\n------------------------------------------------------------------------\n\n# Part 7: KDE Baseline Comparison\n\n## Calculating KDE Baseline\n\n```{r kde_baseline}\n# Create point pattern\ngraffiti_coords <- st_coordinates(graffiti_utm)\n\n# Create window\nwindow <- owin(xrange = range(graffiti_coords[, 1]),\n               yrange = range(graffiti_coords[, 2]))\n\n# Create point pattern\ngraffiti_ppp <- ppp(x = graffiti_coords[, 1],\n                    y = graffiti_coords[, 2],\n                    window = window)\n\n# Calculate KDE\nkde_2017 <- density(graffiti_ppp, sigma = bw.diggle(graffiti_ppp))\nkde_raster <- raster(kde_2017)\n\n# Extract to grid\ngrid_centroids <- st_centroid(graffiti_grid)\nkde_values <- raster::extract(kde_raster, as_Spatial(grid_centroids))\n\n# Normalize\nkde_grid_counts <- kde_values * (500 * 500) / sum(kde_values, na.rm = TRUE) * \n                   sum(graffiti_grid$n_graffiti)\n\n# Calculate errors\nkde_errors <- graffiti_grid %>%\n  st_drop_geometry() %>%\n  mutate(\n    predicted_kde = kde_grid_counts,\n    error_kde = n_graffiti - predicted_kde,\n    abs_error_kde = abs(error_kde),\n    squared_error_kde = error_kde^2\n  ) %>%\n  na.omit()\n\nmae_kde <- mean(kde_errors$abs_error_kde)\nrmse_kde <- sqrt(mean(kde_errors$squared_error_kde))\n\ncat(\"KDE BASELINE\\n\")\ncat(strrep(\"=\", 50), \"\\n\")\ncat(\"MAE:\", round(mae_kde, 3), \"\\n\")\ncat(\"RMSE:\", round(rmse_kde, 3), \"\\n\")\n```\n\n------------------------------------------------------------------------\n\n# Part 8: Final Model Comparison\n\n## Comprehensive Comparison\n\n```{r final_comparison, fig.width=12, fig.height=6}\n# Compare all methods\ncomparison <- tibble(\n  Method = c(\n    paste(\"Spatial CV -\", model_name),\n    \"Temporal (2018)\",\n    \"KDE Baseline\"\n  ),\n  MAE = c(mae, mae_2018, mae_kde),\n  RMSE = c(rmse, rmse_2018, rmse_kde)\n)\n\ncat(\"FINAL MODEL COMPARISON\\n\")\ncat(strrep(\"=\", 50), \"\\n\")\nprint(comparison)\n\ncat(\"\\nImprovement Over KDE Baseline:\\n\")\ncat(\"Spatial CV:\", round((1 - mae/mae_kde)*100, 1), \"%\\n\")\ncat(\"Temporal:\", round((1 - mae_2018/mae_kde)*100, 1), \"%\\n\")\n\n# Visualize comparison\ncomparison_long <- comparison %>%\n  pivot_longer(cols = c(MAE, RMSE), names_to = \"Metric\", values_to = \"Value\")\n\nggplot(comparison_long, aes(x = Method, y = Value, fill = Metric)) +\n  geom_col(position = \"dodge\", alpha = 0.8, color = \"black\") +\n  geom_text(aes(label = round(Value, 2)), position = position_dodge(width = 0.9), \n            vjust = -0.3, size = 3.5) +\n  theme_minimal() +\n  labs(\n    title = \"Final Model Comparison: Error Metrics\",\n    y = \"Error (lower is better)\"\n  ) +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme(\n    plot.title = element_text(size = 13, face = \"bold\"),\n    axis.text.x = element_text(angle = 30, hjust = 1)\n  )\n```\n\n------------------------------------------------------------------------\n\n# Part 9: Error Analysis and Performance Mapping\n\n## Mapping Prediction Errors\n\n```{r error_mapping, fig.width=14, fig.height=8}\n# Add predictions back to grid\ngraffiti_grid_errors <- graffiti_grid %>%\n  left_join(\n    cv_results %>%\n      group_by(grid_id) %>%\n      summarise(\n        predicted = mean(predicted, na.rm = TRUE),\n        error = mean(error, na.rm = TRUE),\n        abs_error = mean(abs_error, na.rm = TRUE),\n        .groups = \"drop\"\n      ),\n    by = \"grid_id\"\n  )\n\n# Map absolute errors\np1 <- ggplot() +\n  geom_sf(data = graffiti_grid_errors, aes(fill = abs_error), color = NA) +\n  geom_sf(data = chicago_utm, fill = NA, color = \"black\", linewidth = 0.5) +\n  scale_fill_viridis_c(name = \"Absolute Error\", option = \"magma\", na.value = \"white\") +\n  theme_minimal() +\n  labs(\n    title = \"Geographic Distribution of Absolute Prediction Errors\",\n    x = \"UTM Easting (m)\",\n    y = \"UTM Northing (m)\"\n  ) +\n  theme(plot.title = element_text(size = 12, face = \"bold\"))\n\n# Map signed errors\np2 <- ggplot() +\n  geom_sf(data = graffiti_grid_errors, aes(fill = error), color = NA) +\n  geom_sf(data = chicago_utm, fill = NA, color = \"black\", linewidth = 0.5) +\n  scale_fill_distiller(\n    name = \"Error\",\n    type = \"div\",\n    palette = \"RdBu\",\n    na.value = \"white\"\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Signed Errors: Red=Underpredicted, Blue=Overpredicted\",\n    x = \"UTM Easting (m)\",\n    y = \"UTM Northing (m)\"\n  ) +\n  theme(plot.title = element_text(size = 12, face = \"bold\"))\n\ngridExtra::grid.arrange(p1, p2, ncol = 2)\n```\n\n## Performance by Observed Count Level\n\n```{r performance_by_count}\n# Analyze error patterns\nerror_by_count <- cv_results %>%\n  mutate(count_bin = cut(observed, \n                        breaks = c(-Inf, 0, 5, 10, 20, Inf),\n                        labels = c(\"0\", \"1-5\", \"6-10\", \"11-20\", \"20+\"))) %>%\n  group_by(count_bin) %>%\n  summarise(\n    n = n(),\n    MAE = mean(abs_error, na.rm = TRUE),\n    RMSE = sqrt(mean(squared_error, na.rm = TRUE)),\n    .groups = \"drop\"\n  )\n\ncat(\"Error Metrics by Observed Count Level:\\n\\n\")\nprint(error_by_count)\n\nggplot(error_by_count, aes(x = count_bin)) +\n  geom_col(aes(y = MAE), fill = \"#E31C23\", alpha = 0.7) +\n  geom_point(aes(y = RMSE), color = \"#0073C2\", size = 4) +\n  theme_minimal() +\n  labs(\n    title = \"Prediction Error by Observed Graffiti Count Level\",\n    x = \"Observed Count Range\",\n    y = \"Error Metric\",\n    subtitle = \"Bars = MAE | Points = RMSE\"\n  ) +\n  theme(plot.title = element_text(size = 12, face = \"bold\"))\n```\n\n------------------------------------------------------------------------\n\n# Summary and Conclusions\n\n## Key Findings\n\n```{r summary}\ncat(\"ANALYSIS SUMMARY\\n\")\ncat(strrep(\"=\", 50), \"\\n\\n\")\n\ncat(\"1. DATA OVERVIEW\\n\")\ncat(\"   • Graffiti requests analyzed:\", nrow(graffiti_utm), \"\\n\")\ncat(\"   • Grid cells created:\", nrow(graffiti_grid), \"\\n\")\ncat(\"   • Cells with graffiti:\", sum(graffiti_grid$n_graffiti > 0), \"\\n\\n\")\n\ncat(\"2. SPATIAL PATTERNS\\n\")\ncat(\"   • Significant clusters identified:\", \n    sum(graffiti_grid$local_i_pval < 0.05), \"\\n\")\ncat(\"   • Hotspot areas (High-High):\", \n    sum(graffiti_grid$moran_cluster == \"High-High\"), \"\\n\")\ncat(\"   • Coldspot areas (Low-Low):\", \n    sum(graffiti_grid$moran_cluster == \"Low-Low\"), \"\\n\\n\")\n\ncat(\"3. MODEL PERFORMANCE\\n\")\ncat(\"   • Selected model:\", model_name, \"\\n\")\ncat(\"   • Spatial CV MAE:\", round(mae, 3), \"\\n\")\ncat(\"   • Spatial CV RMSE:\", round(rmse, 3), \"\\n\")\ncat(\"   • Improvement over KDE:\", round((1 - mae/mae_kde)*100, 1), \"%\\n\\n\")\n\ncat(\"4. TEMPORAL STABILITY\\n\")\ncat(\"   • 2018 predictions MAE:\", round(mae_2018, 3), \"\\n\")\nif (mae_2018 < mae * 1.3) {\n  cat(\"   • Model shows good temporal stability\\n\")\n} else {\n  cat(\"   • Model shows temporal degradation\\n\")\n}\n\ncat(\"\\n5. SPATIAL FEATURES IMPORTANCE\\n\")\nfor (i in 2:nrow(coef_table)) {\n  term <- coef_table$term[i]\n  irr <- coef_table$estimate[i]\n  pval <- coef_table$p.value[i]\n  sig <- ifelse(pval < 0.05, \"***\", \"\")\n  cat(\"   •\", term, \"(IRR =\", round(irr, 3), \") \", sig, \"\\n\")\n}\n```\n\n------------------------------------------------------------------------\n\n**Report Generated:** `r format(Sys.time(), \"%Y-%m-%d %H:%M:%S\")`\n\n**Course:** MUSA 5080 - Public Policy Analytics\\\n**Assignment:** Lab 4 - Spatial Predictive Analysis\\\n**Institution:** University of Pennsylvania\n","srcMarkdownNoYaml":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(\n  echo = TRUE,\n  warning = FALSE,\n  message = FALSE,\n  fig.width = 14,\n  fig.height = 9,\n  dpi = 300\n)\nset.seed(123)\n```\n\n# Introduction\n\nGraffiti represents a persistent challenge to urban neighborhoods, affecting aesthetic quality, public safety perceptions, and property values. Chicago's 311 service request system provides a comprehensive record of graffiti removal requests across the city. This analysis applies spatial predictive modeling to understand whether we can forecast graffiti concentrations using spatial features and count regression models.\n\n**Analysis Goals:** - Develop a spatial predictive model using k-nearest neighbor and Local Moran's I features - Compare Poisson and Negative Binomial regression performance - Validate models using spatial cross-validation (Leave-One-Group-Out) - Test temporal stability using 2018 crime data - Evaluate predictive accuracy against kernel density estimation baseline\n\n------------------------------------------------------------------------\n\n# Part 1: Data Loading and Exploration\n\n## Loading Required Libraries\n\n```{r load_libraries}\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(sf)\nlibrary(sp)\nlibrary(raster)\nlibrary(spdep)\nlibrary(spatstat)\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(viridis)\nlibrary(MASS)\nlibrary(broom)\nlibrary(jsonlite)\nlibrary(httr)\n\ntheme_set(theme_minimal())\n```\n\n## Downloading Graffiti Data from Chicago 311 Portal\n\n```{r load_graffiti_data}\n# Chicago 311 API endpoint for graffiti data\napi_url <- \"https://data.cityofchicago.org/resource/hec5-y4x5.json\"\n\n# Query parameters: download all available data\nparams <- list(\n  \"$limit\" = 50000\n)\n\n# Execute API request\nresponse <- GET(api_url, query = params)\ngraffiti_raw <- fromJSON(content(response, \"text\"))\ngraffiti_df <- as_tibble(graffiti_raw)\n\ncat(\"Raw Graffiti Data Summary:\\n\")\ncat(\"Total Records:\", nrow(graffiti_df), \"\\n\")\ncat(\"Variables:\", ncol(graffiti_df), \"\\n\\n\")\n\n# Check available columns\ncat(\"Available columns:\\n\")\nprint(colnames(graffiti_df))\n```\n\n## Data Cleaning and Preparation\n\n```{r clean_graffiti_data}\n# Clean and prepare graffiti data\ngraffiti_clean <- graffiti_df %>%\n  filter(!is.na(longitude) & !is.na(latitude)) %>%\n  mutate(\n    longitude = as.numeric(longitude),\n    latitude = as.numeric(latitude),\n    creation_date = as.POSIXct(creation_date),\n    year = year(creation_date),\n    month = month(creation_date),\n    date = as_date(creation_date)\n  ) %>%\n  filter(longitude > -88.5 & longitude < -87.5,\n         latitude > 41.6 & latitude < 42.1)\n\ncat(\"Data Cleaning Summary:\\n\")\ncat(\"Records after cleaning: \", nrow(graffiti_clean), \"\\n\")\nif(nrow(graffiti_clean) > 0) {\n  cat(\"Date range: \", min(graffiti_clean$date, na.rm = TRUE), \n      \" to \", max(graffiti_clean$date, na.rm = TRUE), \"\\n\")\n}\n\nhead(graffiti_clean, 5)\n```\n\n## Converting to Spatial Object\n\n```{r convert_to_sf}\n# Convert to sf object (WGS84)\ngraffiti_wgs84 <- st_as_sf(graffiti_clean,\n                            coords = c(\"longitude\", \"latitude\"),\n                            crs = 4326)\n\n# Project to UTM Zone 16N for accurate distance calculations\ngraffiti_utm <- st_transform(graffiti_wgs84, crs = 32616)\n\ncat(\"Spatial Object Created:\\n\")\ncat(\"Total features:\", nrow(graffiti_utm), \"\\n\")\n```\n\n## Loading Chicago City Boundary\n\n```{r load_chicago_boundary}\n# Load Chicago boundary from city's open data portal\nchicago_url <- \"https://data.cityofchicago.org/api/geospatial/igwz-8jzy?method=export&format=GeoJSON\"\nchicago_boundary <- st_read(chicago_url, quiet = TRUE)\n\n# Project to UTM Zone 16N\nchicago_utm <- st_transform(chicago_boundary, crs = 32616)\n\ncat(\"Chicago Boundary Loaded\\n\")\ncat(\"Area:\", round(as.numeric(st_area(chicago_utm))/1e6, 1), \"km²\\n\")\n```\n\n## Visualizing Spatial Distribution\n\n```{r plot_graffiti_points, fig.width=12, fig.height=8}\n# Create base map showing all graffiti points\nggplot() +\n  geom_sf(data = chicago_utm, fill = NA, color = \"black\", linewidth = 0.8) +\n  geom_sf(data = graffiti_utm, color = \"#E31C23\", size = 0.8, alpha = 0.3) +\n  theme_minimal() +\n  labs(\n    title = \"Spatial Distribution of Graffiti Removal Requests\",\n    subtitle = paste(\"Total requests:\", nrow(graffiti_utm)),\n    x = \"UTM Easting (m)\",\n    y = \"UTM Northing (m)\"\n  ) +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 11),\n    axis.text = element_text(size = 9)\n  )\n```\n\n## Temporal Patterns\n\n```{r temporal_analysis, fig.width=12, fig.height=6}\n# Calculate monthly statistics\nmonthly_stats <- graffiti_clean %>%\n  group_by(month) %>%\n  summarise(\n    count = n(),\n    avg_per_day = n() / n_distinct(date),\n    .groups = \"drop\"\n  ) %>%\n  mutate(month_name = month.abb[month])\n\n# Visualize monthly distribution\nggplot(monthly_stats, aes(x = reorder(month_name, month), y = count)) +\n  geom_col(fill = \"#E31C23\", alpha = 0.8, color = \"black\", linewidth = 0.3) +\n  geom_text(aes(label = count), vjust = -0.3, size = 3.5, fontface = \"bold\") +\n  theme_minimal() +\n  labs(\n    title = \"Monthly Distribution of Graffiti Requests\",\n    x = \"Month\",\n    y = \"Number of Requests\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(size = 13, face = \"bold\")\n  )\n\ncat(\"\\nTemporal Summary:\\n\")\nprint(monthly_stats)\n```\n\n------------------------------------------------------------------------\n\n# Part 2: Fishnet Grid Creation\n\n## Creating 500m × 500m Grid\n\n```{r create_fishnet_grid}\n# Create regular grid covering Chicago\nfishnet_full <- st_make_grid(\n  chicago_utm,\n  cellsize = 500,\n  square = TRUE,\n  what = \"polygons\"\n) %>%\n  st_as_sf() %>%\n  mutate(grid_id = row_number())\n\n# Keep only grid cells intersecting Chicago boundary\nfishnet_chicago <- fishnet_full[chicago_utm, ]\n\ncat(\"Fishnet Grid Created:\\n\")\ncat(\"Total grid cells:\", nrow(fishnet_chicago), \"\\n\")\ncat(\"Cell size: 500m × 500m\\n\")\n```\n\n## Aggregating Graffiti Counts to Grid\n\n```{r aggregate_graffiti_to_grid}\n# Aggregate graffiti points to grid cells\ngraffiti_grid <- fishnet_chicago %>%\n  st_join(graffiti_utm, join = st_contains) %>%\n  group_by(grid_id) %>%\n  summarise(\n    n_graffiti = n(),\n    .groups = \"drop\"\n  ) %>%\n  mutate(n_graffiti = ifelse(is.na(n_graffiti), 0, n_graffiti))\n\ncat(\"Grid Aggregation Complete:\\n\")\ncat(\"Total cells:\", nrow(graffiti_grid), \"\\n\")\ncat(\"Cells with graffiti:\", sum(graffiti_grid$n_graffiti > 0), \"\\n\")\ncat(\"Mean per cell:\", round(mean(graffiti_grid$n_graffiti), 2), \"\\n\\n\")\n\nprint(summary(graffiti_grid$n_graffiti))\n```\n\n## Visualizing Grid Aggregation\n\n```{r plot_grid_distribution, fig.width=14, fig.height=8}\n# Map showing graffiti counts per grid cell\np1 <- ggplot() +\n  geom_sf(data = graffiti_grid, aes(fill = n_graffiti), color = NA) +\n  geom_sf(data = chicago_utm, fill = NA, color = \"black\", linewidth = 0.5) +\n  scale_fill_viridis_c(name = \"Requests\", option = \"plasma\") +\n  theme_minimal() +\n  labs(\n    title = \"Graffiti Count Aggregation to 500m Grid\",\n    x = \"UTM Easting (m)\",\n    y = \"UTM Northing (m)\"\n  ) +\n  theme(plot.title = element_text(size = 13, face = \"bold\"))\n\n# Histogram of counts\np2 <- ggplot(graffiti_grid, aes(x = n_graffiti)) +\n  geom_histogram(bins = 40, fill = \"#E31C23\", alpha = 0.8, color = \"black\") +\n  theme_minimal() +\n  labs(\n    title = \"Distribution of Graffiti Counts\",\n    x = \"Requests per Cell\",\n    y = \"Frequency\"\n  ) +\n  theme(plot.title = element_text(size = 12, face = \"bold\"))\n\ngridExtra::grid.arrange(p1, p2, ncol = 2)\n```\n\n------------------------------------------------------------------------\n\n# Part 3: Spatial Features Construction\n\n## Creating Spatial Weights Matrix and Features\n\n```{r spatial_features}\n# Step 1: Ensure graffiti_grid is sf with grid_id\ngraffiti_grid <- graffiti_grid %>%\n  mutate(grid_id = row_number())\n\n# Step 2: Convert to sp object (required by spdep)\ngraffiti_sp <- as_Spatial(graffiti_grid)\n\n# Step 3: Create k-nearest neighbors weight matrix\nknn_neighbors <- knearneigh(coordinates(graffiti_sp), k = 5)\nknn_weights <- knn2nb(knn_neighbors, sym = TRUE)\nknn_weights_std <- nb2listw(knn_weights, style = \"W\")\n\ncat(\"Spatial Weights Matrix Created (k=5 nearest neighbors)\\n\")\n\n# Step 4: Calculate k-NN feature (neighbor mean)\nneighbor_lags <- lag.listw(knn_weights_std, graffiti_grid$n_graffiti)\n\n# Step 5: Calculate Local Moran's I\nlocal_moran <- localmoran(graffiti_grid$n_graffiti, knn_weights_std)\n\n# Step 6: Calculate distance to hotspot\nhotspot_threshold <- quantile(graffiti_grid$n_graffiti, 0.75)\nhotspots <- graffiti_grid %>% filter(n_graffiti >= hotspot_threshold)\nhotspot_center <- st_centroid(st_union(hotspots))\ndist_to_hotspot <- as.numeric(st_distance(graffiti_grid, hotspot_center)) / 1000\n\n# Step 7: Add all features to graffiti_grid\ngraffiti_grid <- graffiti_grid %>%\n  mutate(\n    neighbor_mean = neighbor_lags,\n    local_i = local_moran[, 1],\n    local_i_pval = local_moran[, 5],\n    dist_to_hotspot = dist_to_hotspot,\n    moran_cluster = case_when(\n      local_i_pval >= 0.05 ~ \"Not significant\",\n      local_i >= 0 & n_graffiti >= median(n_graffiti) ~ \"High-High\",\n      local_i >= 0 & n_graffiti < median(n_graffiti) ~ \"Low-Low\",\n      local_i < 0 & n_graffiti >= median(n_graffiti) ~ \"High-Low\",\n      TRUE ~ \"Low-High\"\n    )\n  )\n\ncat(\"\\nSpatial Features Added:\\n\")\ncat(\"neighbor_mean: Average graffiti count in 5 nearest neighbors\\n\")\ncat(\"local_i: Local Moran's I statistic\\n\")\ncat(\"dist_to_hotspot: Distance to graffiti hotspot (km)\\n\")\ncat(\"moran_cluster: Classification of spatial clusters\\n\")\ncat(\"\\nFirst 5 rows:\\n\")\n\nfeature_summary <- graffiti_grid %>% \n  st_drop_geometry()\n\nhead(feature_summary, 5)\n```\n\n## Visualizing Hotspots and Coldspots\n\n```{r plot_local_morans, fig.width=12, fig.height=8}\nggplot() +\n  geom_sf(data = graffiti_grid, aes(fill = moran_cluster), color = NA) +\n  geom_sf(data = chicago_utm, fill = NA, color = \"black\", linewidth = 0.5) +\n  scale_fill_manual(\n    name = \"Cluster Type\",\n    values = c(\n      \"High-High\" = \"#d73027\",\n      \"Low-Low\" = \"#91bfdb\",\n      \"High-Low\" = \"#fee090\",\n      \"Low-High\" = \"#a6d96a\",\n      \"Not significant\" = \"#f7f7f7\"\n    )\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Local Moran's I: Graffiti Hotspots and Coldspots\",\n    x = \"UTM Easting (m)\",\n    y = \"UTM Northing (m)\"\n  ) +\n  theme(plot.title = element_text(size = 13, face = \"bold\"))\n\ncat(\"\\nCluster Distribution:\\n\")\nprint(table(graffiti_grid$moran_cluster))\n```\n\n------------------------------------------------------------------------\n\n# Part 4: Count Regression Models\n\n## Preparing Data for Modeling\n\n```{r model_preparation}\n# Prepare data for modeling\nmodel_data <- graffiti_grid %>%\n  st_drop_geometry() %>%\n  na.omit()\n\ncat(\"Model Data Prepared:\\n\")\ncat(\"Sample size:\", nrow(model_data), \"\\n\")\ncat(\"Dependent variable (n_graffiti):\\n\")\nprint(summary(model_data$n_graffiti))\n\ncat(\"\\nOverdispersion check:\\n\")\ncat(\"Mean:\", mean(model_data$n_graffiti), \"\\n\")\ncat(\"Variance:\", var(model_data$n_graffiti), \"\\n\")\ncat(\"Variance/Mean ratio:\", round(var(model_data$n_graffiti)/mean(model_data$n_graffiti), 2), \"\\n\")\n```\n\n## Poisson Regression\n\n```{r poisson_model}\n# Fit Poisson regression\npoisson_model <- glm(\n  n_graffiti ~ neighbor_mean + local_i + dist_to_hotspot,\n  family = poisson(link = \"log\"),\n  data = model_data\n)\n\ncat(\"POISSON REGRESSION RESULTS\\n\")\ncat(strrep(\"=\", 50), \"\\n\\n\")\nprint(summary(poisson_model))\n\n# Extract metrics\npoisson_aic <- AIC(poisson_model)\npoisson_deviance <- deviance(poisson_model)\npoisson_dispersion <- poisson_deviance / df.residual(poisson_model)\n\ncat(\"\\nModel Fit Statistics:\\n\")\ncat(\"AIC:\", round(poisson_aic, 2), \"\\n\")\ncat(\"Dispersion statistic:\", round(poisson_dispersion, 3), \"\\n\")\n```\n\n## Negative Binomial Regression\n\n```{r negative_binomial_model}\n# Fit Negative Binomial regression\nnb_model <- glm.nb(\n  n_graffiti ~ neighbor_mean + local_i + dist_to_hotspot,\n  data = model_data\n)\n\ncat(\"\\nNEGATIVE BINOMIAL REGRESSION RESULTS\\n\")\ncat(strrep(\"=\", 50), \"\\n\\n\")\nprint(summary(nb_model))\n\n# Extract metrics\nnb_aic <- AIC(nb_model)\nnb_deviance <- deviance(nb_model)\n\ncat(\"\\nModel Fit Statistics:\\n\")\ncat(\"AIC:\", round(nb_aic, 2), \"\\n\")\n```\n\n## Model Comparison\n\n```{r model_comparison}\n# Compare models\ncat(\"\\nMODEL COMPARISON\\n\")\ncat(strrep(\"=\", 50), \"\\n\")\ncat(\"Poisson AIC:\", round(poisson_aic, 2), \"\\n\")\ncat(\"Negative Binomial AIC:\", round(nb_aic, 2), \"\\n\")\ncat(\"Difference:\", round(poisson_aic - nb_aic, 2), \"\\n\\n\")\n\nif (nb_aic < poisson_aic) {\n  cat(\"Decision: Negative Binomial model preferred (lower AIC)\\n\")\n  selected_model <- nb_model\n  model_name <- \"Negative Binomial\"\n} else {\n  cat(\"Decision: Poisson model preferred (lower AIC)\\n\")\n  selected_model <- poisson_model\n  model_name <- \"Poisson\"\n}\n\n# Extract coefficients\ncoef_table <- tidy(selected_model, exponentiate = TRUE, conf.int = TRUE)\n\ncat(\"\\n\\nSelected Model Coefficients (Exponentiated - Incidence Rate Ratios):\\n\")\nprint(coef_table)\n```\n\n------------------------------------------------------------------------\n\n# Part 5: Spatial Cross-Validation\n\n## Setting Up Spatial Folds\n\n```{r spatial_cv_setup}\n# Create spatial folds\nset.seed(123)\nn_folds <- 5\n\ncentroids <- st_coordinates(st_centroid(graffiti_grid))\nspatial_folds <- kmeans(centroids, centers = n_folds)$cluster\n\ncv_data <- model_data %>%\n  mutate(fold = spatial_folds[row_number()])\n\ncat(\"Spatial Cross-Validation Setup:\\n\")\ncat(\"Number of folds:\", n_folds, \"\\n\")\ncat(\"Fold sizes:\\n\")\nprint(table(cv_data$fold))\n```\n\n## Running Cross-Validation\n\n```{r run_spatial_cv}\n# Cross-validation loop\ncv_results <- tibble()\n\nfor (fold_num in 1:n_folds) {\n  train_data <- cv_data %>% filter(fold != fold_num)\n  test_data <- cv_data %>% filter(fold == fold_num)\n  \n  # Fit model on training data\n  if (model_name == \"Negative Binomial\") {\n    fold_model <- glm.nb(\n      n_graffiti ~ neighbor_mean + local_i + dist_to_hotspot,\n      data = train_data\n    )\n  } else {\n    fold_model <- glm(\n      n_graffiti ~ neighbor_mean + local_i + dist_to_hotspot,\n      family = poisson(link = \"log\"),\n      data = train_data\n    )\n  }\n  \n  # Predictions\n  pred <- predict(fold_model, newdata = test_data, type = \"response\")\n  \n  fold_results <- test_data %>%\n    mutate(\n      fold = fold_num,\n      observed = n_graffiti,\n      predicted = pred,\n      error = observed - predicted,\n      abs_error = abs(error),\n      squared_error = error^2\n    )\n  \n  cv_results <- bind_rows(cv_results, fold_results)\n}\n\ncat(\"Cross-Validation Complete:\\n\")\ncat(\"Total predictions:\", nrow(cv_results), \"\\n\")\n```\n\n## Cross-Validation Error Metrics\n\n```{r cv_error_metrics}\n# Calculate error metrics\nmae <- mean(cv_results$abs_error, na.rm = TRUE)\nrmse <- sqrt(mean(cv_results$squared_error, na.rm = TRUE))\nme <- mean(cv_results$error, na.rm = TRUE)\n\ncat(\"SPATIAL CROSS-VALIDATION RESULTS\\n\")\ncat(strrep(\"=\", 50), \"\\n\")\ncat(\"Mean Absolute Error (MAE):\", round(mae, 3), \"\\n\")\ncat(\"Root Mean Squared Error (RMSE):\", round(rmse, 3), \"\\n\")\ncat(\"Mean Error (ME):\", round(me, 3), \"\\n\")\n```\n\n## Visualizing CV Results\n\n```{r plot_cv_results, fig.width=14, fig.height=8}\n# Observed vs Predicted\np1 <- ggplot(cv_results, aes(x = observed, y = predicted)) +\n  geom_point(alpha = 0.5, color = \"#E31C23\") +\n  geom_abline(intercept = 0, slope = 1, color = \"blue\", linetype = \"dashed\") +\n  theme_minimal() +\n  labs(\n    title = \"Spatial CV: Observed vs Predicted\",\n    x = \"Observed\",\n    y = \"Predicted\",\n    subtitle = paste(\"MAE =\", round(mae, 2))\n  ) +\n  theme(plot.title = element_text(size = 12, face = \"bold\"))\n\n# Residuals\np2 <- ggplot(cv_results, aes(x = error)) +\n  geom_histogram(bins = 30, fill = \"#E31C23\", alpha = 0.7) +\n  geom_vline(xintercept = 0, color = \"blue\", linetype = \"dashed\") +\n  theme_minimal() +\n  labs(\n    title = \"Residuals Distribution\",\n    x = \"Prediction Error\",\n    y = \"Frequency\"\n  ) +\n  theme(plot.title = element_text(size = 12, face = \"bold\"))\n\ngridExtra::grid.arrange(p1, p2, ncol = 2)\n```\n\n------------------------------------------------------------------------\n\n# Part 6: Temporal Validation (2018 Data)\n\n## Loading 2018 Crime Data\n\n```{r load_2018_crimes}\n# Download 2018 crimes data\ncrime_url <- \"https://data.cityofchicago.org/resource/3i3m-jwuy.json\"\n\n# Simple query without complex filters\nresponse_2018 <- GET(crime_url, query = list(\"$limit\" = 50000))\ncrime_2018_raw <- fromJSON(content(response_2018, \"text\"))\ncrime_2018_df <- as_tibble(crime_2018_raw)\n\ncat(\"2018 Crime Data Loaded:\\n\")\ncat(\"Total records:\", nrow(crime_2018_df), \"\\n\")\ncat(\"Columns:\", ncol(crime_2018_df), \"\\n\")\n```\n\n## Preparing 2018 Data\n\n```{r prepare_2018_data}\n# Clean 2018 data\ncrime_2018_clean <- crime_2018_df %>%\n  filter(!is.na(longitude) & !is.na(latitude)) %>%\n  mutate(\n    longitude = as.numeric(longitude),\n    latitude = as.numeric(latitude)\n  ) %>%\n  filter(longitude > -88.5 & longitude < -87.5,\n         latitude > 41.6 & latitude < 42.1)\n\n# Convert to sf\ncrime_2018_wgs84 <- st_as_sf(crime_2018_clean,\n                             coords = c(\"longitude\", \"latitude\"),\n                             crs = 4326)\n\ncrime_2018_utm <- st_transform(crime_2018_wgs84, crs = 32616)\n\ncat(\"2018 Data Cleaned:\\n\")\ncat(\"Records:\", nrow(crime_2018_utm), \"\\n\")\n```\n\n## Aggregating 2018 to Same Grid\n\n```{r aggregate_2018_to_grid}\n# Aggregate to grid\ncrime_2018_grid <- fishnet_chicago %>%\n  st_join(crime_2018_utm, join = st_contains) %>%\n  group_by(grid_id) %>%\n  summarise(\n    n_crime = n(),\n    .groups = \"drop\"\n  ) %>%\n  mutate(n_crime = ifelse(is.na(n_crime), 0, n_crime))\n\ncat(\"2018 Aggregation:\\n\")\ncat(\"Total cells:\", nrow(crime_2018_grid), \"\\n\")\ncat(\"Cells with crimes:\", sum(crime_2018_grid$n_crime > 0), \"\\n\")\n```\n\n## Predicting 2018 with 2017 Model\n\n```{r temporal_prediction}\n# Prepare features\ncrime_2018_features <- crime_2018_grid %>%\n  st_drop_geometry() %>%\n  mutate(\n    observed_2018 = n_crime\n  ) %>%\n  left_join(\n    model_data %>% mutate(grid_id = row_number()),\n    by = \"grid_id\"\n  ) %>%\n  na.omit()\n\ncat(\"2018 Features Prepared:\\n\")\ncat(\"Records:\", nrow(crime_2018_features), \"\\n\")\n\n# Make predictions using 2017 model\npred_2018 <- predict(selected_model, \n                     newdata = crime_2018_features, \n                     type = \"response\")\n\ntemporal_results <- crime_2018_features %>%\n  mutate(\n    predicted_2018 = pred_2018,\n    error_2018 = observed_2018 - predicted_2018,\n    abs_error_2018 = abs(error_2018),\n    squared_error_2018 = error_2018^2\n  )\n\ncat(\"Temporal Validation:\\n\")\ncat(\"Predictions made:\", nrow(temporal_results), \"\\n\")\n```\n\n## Temporal Validation Metrics\n\n```{r temporal_error_metrics}\n# Calculate 2018 metrics\nmae_2018 <- mean(temporal_results$abs_error_2018)\nrmse_2018 <- sqrt(mean(temporal_results$squared_error_2018))\n\ncat(\"TEMPORAL VALIDATION (2018)\\n\")\ncat(strrep(\"=\", 50), \"\\n\")\ncat(\"MAE:\", round(mae_2018, 3), \"\\n\")\ncat(\"RMSE:\", round(rmse_2018, 3), \"\\n\")\n```\n\n------------------------------------------------------------------------\n\n# Part 7: KDE Baseline Comparison\n\n## Calculating KDE Baseline\n\n```{r kde_baseline}\n# Create point pattern\ngraffiti_coords <- st_coordinates(graffiti_utm)\n\n# Create window\nwindow <- owin(xrange = range(graffiti_coords[, 1]),\n               yrange = range(graffiti_coords[, 2]))\n\n# Create point pattern\ngraffiti_ppp <- ppp(x = graffiti_coords[, 1],\n                    y = graffiti_coords[, 2],\n                    window = window)\n\n# Calculate KDE\nkde_2017 <- density(graffiti_ppp, sigma = bw.diggle(graffiti_ppp))\nkde_raster <- raster(kde_2017)\n\n# Extract to grid\ngrid_centroids <- st_centroid(graffiti_grid)\nkde_values <- raster::extract(kde_raster, as_Spatial(grid_centroids))\n\n# Normalize\nkde_grid_counts <- kde_values * (500 * 500) / sum(kde_values, na.rm = TRUE) * \n                   sum(graffiti_grid$n_graffiti)\n\n# Calculate errors\nkde_errors <- graffiti_grid %>%\n  st_drop_geometry() %>%\n  mutate(\n    predicted_kde = kde_grid_counts,\n    error_kde = n_graffiti - predicted_kde,\n    abs_error_kde = abs(error_kde),\n    squared_error_kde = error_kde^2\n  ) %>%\n  na.omit()\n\nmae_kde <- mean(kde_errors$abs_error_kde)\nrmse_kde <- sqrt(mean(kde_errors$squared_error_kde))\n\ncat(\"KDE BASELINE\\n\")\ncat(strrep(\"=\", 50), \"\\n\")\ncat(\"MAE:\", round(mae_kde, 3), \"\\n\")\ncat(\"RMSE:\", round(rmse_kde, 3), \"\\n\")\n```\n\n------------------------------------------------------------------------\n\n# Part 8: Final Model Comparison\n\n## Comprehensive Comparison\n\n```{r final_comparison, fig.width=12, fig.height=6}\n# Compare all methods\ncomparison <- tibble(\n  Method = c(\n    paste(\"Spatial CV -\", model_name),\n    \"Temporal (2018)\",\n    \"KDE Baseline\"\n  ),\n  MAE = c(mae, mae_2018, mae_kde),\n  RMSE = c(rmse, rmse_2018, rmse_kde)\n)\n\ncat(\"FINAL MODEL COMPARISON\\n\")\ncat(strrep(\"=\", 50), \"\\n\")\nprint(comparison)\n\ncat(\"\\nImprovement Over KDE Baseline:\\n\")\ncat(\"Spatial CV:\", round((1 - mae/mae_kde)*100, 1), \"%\\n\")\ncat(\"Temporal:\", round((1 - mae_2018/mae_kde)*100, 1), \"%\\n\")\n\n# Visualize comparison\ncomparison_long <- comparison %>%\n  pivot_longer(cols = c(MAE, RMSE), names_to = \"Metric\", values_to = \"Value\")\n\nggplot(comparison_long, aes(x = Method, y = Value, fill = Metric)) +\n  geom_col(position = \"dodge\", alpha = 0.8, color = \"black\") +\n  geom_text(aes(label = round(Value, 2)), position = position_dodge(width = 0.9), \n            vjust = -0.3, size = 3.5) +\n  theme_minimal() +\n  labs(\n    title = \"Final Model Comparison: Error Metrics\",\n    y = \"Error (lower is better)\"\n  ) +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme(\n    plot.title = element_text(size = 13, face = \"bold\"),\n    axis.text.x = element_text(angle = 30, hjust = 1)\n  )\n```\n\n------------------------------------------------------------------------\n\n# Part 9: Error Analysis and Performance Mapping\n\n## Mapping Prediction Errors\n\n```{r error_mapping, fig.width=14, fig.height=8}\n# Add predictions back to grid\ngraffiti_grid_errors <- graffiti_grid %>%\n  left_join(\n    cv_results %>%\n      group_by(grid_id) %>%\n      summarise(\n        predicted = mean(predicted, na.rm = TRUE),\n        error = mean(error, na.rm = TRUE),\n        abs_error = mean(abs_error, na.rm = TRUE),\n        .groups = \"drop\"\n      ),\n    by = \"grid_id\"\n  )\n\n# Map absolute errors\np1 <- ggplot() +\n  geom_sf(data = graffiti_grid_errors, aes(fill = abs_error), color = NA) +\n  geom_sf(data = chicago_utm, fill = NA, color = \"black\", linewidth = 0.5) +\n  scale_fill_viridis_c(name = \"Absolute Error\", option = \"magma\", na.value = \"white\") +\n  theme_minimal() +\n  labs(\n    title = \"Geographic Distribution of Absolute Prediction Errors\",\n    x = \"UTM Easting (m)\",\n    y = \"UTM Northing (m)\"\n  ) +\n  theme(plot.title = element_text(size = 12, face = \"bold\"))\n\n# Map signed errors\np2 <- ggplot() +\n  geom_sf(data = graffiti_grid_errors, aes(fill = error), color = NA) +\n  geom_sf(data = chicago_utm, fill = NA, color = \"black\", linewidth = 0.5) +\n  scale_fill_distiller(\n    name = \"Error\",\n    type = \"div\",\n    palette = \"RdBu\",\n    na.value = \"white\"\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Signed Errors: Red=Underpredicted, Blue=Overpredicted\",\n    x = \"UTM Easting (m)\",\n    y = \"UTM Northing (m)\"\n  ) +\n  theme(plot.title = element_text(size = 12, face = \"bold\"))\n\ngridExtra::grid.arrange(p1, p2, ncol = 2)\n```\n\n## Performance by Observed Count Level\n\n```{r performance_by_count}\n# Analyze error patterns\nerror_by_count <- cv_results %>%\n  mutate(count_bin = cut(observed, \n                        breaks = c(-Inf, 0, 5, 10, 20, Inf),\n                        labels = c(\"0\", \"1-5\", \"6-10\", \"11-20\", \"20+\"))) %>%\n  group_by(count_bin) %>%\n  summarise(\n    n = n(),\n    MAE = mean(abs_error, na.rm = TRUE),\n    RMSE = sqrt(mean(squared_error, na.rm = TRUE)),\n    .groups = \"drop\"\n  )\n\ncat(\"Error Metrics by Observed Count Level:\\n\\n\")\nprint(error_by_count)\n\nggplot(error_by_count, aes(x = count_bin)) +\n  geom_col(aes(y = MAE), fill = \"#E31C23\", alpha = 0.7) +\n  geom_point(aes(y = RMSE), color = \"#0073C2\", size = 4) +\n  theme_minimal() +\n  labs(\n    title = \"Prediction Error by Observed Graffiti Count Level\",\n    x = \"Observed Count Range\",\n    y = \"Error Metric\",\n    subtitle = \"Bars = MAE | Points = RMSE\"\n  ) +\n  theme(plot.title = element_text(size = 12, face = \"bold\"))\n```\n\n------------------------------------------------------------------------\n\n# Summary and Conclusions\n\n## Key Findings\n\n```{r summary}\ncat(\"ANALYSIS SUMMARY\\n\")\ncat(strrep(\"=\", 50), \"\\n\\n\")\n\ncat(\"1. DATA OVERVIEW\\n\")\ncat(\"   • Graffiti requests analyzed:\", nrow(graffiti_utm), \"\\n\")\ncat(\"   • Grid cells created:\", nrow(graffiti_grid), \"\\n\")\ncat(\"   • Cells with graffiti:\", sum(graffiti_grid$n_graffiti > 0), \"\\n\\n\")\n\ncat(\"2. SPATIAL PATTERNS\\n\")\ncat(\"   • Significant clusters identified:\", \n    sum(graffiti_grid$local_i_pval < 0.05), \"\\n\")\ncat(\"   • Hotspot areas (High-High):\", \n    sum(graffiti_grid$moran_cluster == \"High-High\"), \"\\n\")\ncat(\"   • Coldspot areas (Low-Low):\", \n    sum(graffiti_grid$moran_cluster == \"Low-Low\"), \"\\n\\n\")\n\ncat(\"3. MODEL PERFORMANCE\\n\")\ncat(\"   • Selected model:\", model_name, \"\\n\")\ncat(\"   • Spatial CV MAE:\", round(mae, 3), \"\\n\")\ncat(\"   • Spatial CV RMSE:\", round(rmse, 3), \"\\n\")\ncat(\"   • Improvement over KDE:\", round((1 - mae/mae_kde)*100, 1), \"%\\n\\n\")\n\ncat(\"4. TEMPORAL STABILITY\\n\")\ncat(\"   • 2018 predictions MAE:\", round(mae_2018, 3), \"\\n\")\nif (mae_2018 < mae * 1.3) {\n  cat(\"   • Model shows good temporal stability\\n\")\n} else {\n  cat(\"   • Model shows temporal degradation\\n\")\n}\n\ncat(\"\\n5. SPATIAL FEATURES IMPORTANCE\\n\")\nfor (i in 2:nrow(coef_table)) {\n  term <- coef_table$term[i]\n  irr <- coef_table$estimate[i]\n  pval <- coef_table$p.value[i]\n  sig <- ifelse(pval < 0.05, \"***\", \"\")\n  cat(\"   •\", term, \"(IRR =\", round(irr, 3), \") \", sig, \"\\n\")\n}\n```\n\n------------------------------------------------------------------------\n\n**Report Generated:** `r format(Sys.time(), \"%Y-%m-%d %H:%M:%S\")`\n\n**Course:** MUSA 5080 - Public Policy Analytics\\\n**Assignment:** Lab 4 - Spatial Predictive Analysis\\\n**Institution:** University of Pennsylvania\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"show","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"self-contained":true,"highlight-style":"github","output-file":"assignment4.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.33","theme":"cosmo","title":"Spatial Predictive Analysis: Chicago Graffiti Removal 311 Requests","subtitle":"MUSA 5080 Lab Assignment 4","author":"Yanyang Chen","date":"`r Sys.Date()`","editor":"visual"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}