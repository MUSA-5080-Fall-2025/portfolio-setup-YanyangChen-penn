# Changes in Claim Amount
claim_change <- read.csv("eviction_data/changes_claims.csv")
# Demographics
demographics <- read.csv("eviction_data/demographics.csv")
# Hotspots
hotspots <- read.csv("eviction_data/eviction_hotspots.csv")
# Evictions Relative to Baseline
evictions_baseline <- read.csv("eviction_data/filings_relative_baseline.csv")
# Tract Level Filings
tract_filings <- read.csv("eviction_data/tract_level_filings.csv")
# Tract Level Filing Rate
tract_filing_rate <- read.csv("eviction_data/tract_level_filing_rate.csv")
# Eviction Trends
eviction_trends <- read.csv("eviction_data/trends_eviction.csv")
# Monthly Unemployment Rates
unemployment_monthly <- read_xlsx("eviction_data/unemployment_rate_montly.xlsx")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyverse)
library(tidycensus)
library(knitr)
library(tigris)
library(sf)
library(broom)
library(readxl) # some data came in xlsx formata and did not convert to csv cleanly
library(scales)
library(patchwork)
library(here)
library(ggplot2)
# Changes in Claim Amount
claim_change <- read.csv("eviction_data/changes_claims.csv")
# Demographics
demographics <- read.csv("eviction_data/demographics.csv")
# Hotspots
hotspots <- read.csv("eviction_data/eviction_hotspots.csv")
# Evictions Relative to Baseline
evictions_baseline <- read.csv("eviction_data/filings_relative_baseline.csv")
# Tract Level Filings
tract_filings <- read.csv("eviction_data/tract_level_filings.csv")
# Tract Level Filing Rate
tract_filing_rate <- read.csv("eviction_data/tract_level_filing_rate.csv")
# Eviction Trends
eviction_trends <- read.csv("eviction_data/trends_eviction.csv")
# Monthly Unemployment Rates
unemployment_monthly <- read_xlsx("eviction_data/unemployment_rate_montly.xlsx")
# Consumer Price Index
consumer_price_index <- read_xlsx("eviction_data/consumer_price_index_monthly.xlsx")
#Financial Health Data
financial_health <- read_xlsx("eviction_data/financial-health-of-residents-data.xlsx")
# Investigate the data set
head(tract_filings, 50)
# Import Census Tract Geometry
options(tigris_use_cache = TRUE)
# Import for Philadelphia
philadelphia_tracts <- tracts(state = "PA", county = "Philadelphia", year = 2022)
# Look at Results
plot(philadelphia_tracts$geometry)
# Make Sure Format Matches
philadelphia_tracts$GEOID <- as.character(philadelphia_tracts$GEOID)
tract_filings$id <- as.character(tract_filings$id)
# Join
evictions_geo <- philadelphia_tracts %>%
left_join(tract_filings, by = c("GEOID" = "id"))
ggplot(evictions_geo) +
geom_sf(aes(fill = month_rate), color = NA) +
scale_fill_viridis_c(option = "magma") +
labs(
title = "Eviction Rate by Census Tract",
fill = "Eviction Rate"
) +
theme_minimal()
View(unemployment_monthly)
View(tract_filings)
View(tract_filing_rate)
library(spdep)
# Prepare spatial neighbors from census tract geometry
nb <- poly2nb(evictions_geo)
library(spdep)
# Prepare spatial neighbors from census tract geometry
nb <- poly2nb(evictions_geo)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyverse)
library(tidycensus)
library(knitr)
library(tigris)
library(sf)
library(broom)
library(readxl) # some data came in xlsx formata and did not convert to csv cleanly
library(scales)
library(patchwork)
library(here)
library(ggplot2)
# Changes in Claim Amount
claim_change <- read.csv("eviction_data/changes_claims.csv")
# Demographics
demographics <- read.csv("eviction_data/demographics.csv")
# Hotspots
hotspots <- read.csv("eviction_data/eviction_hotspots.csv")
# Evictions Relative to Baseline
evictions_baseline <- read.csv("eviction_data/filings_relative_baseline.csv")
# Tract Level Filings
tract_filings <- read.csv("eviction_data/tract_level_filings.csv")
# Tract Level Filing Rate
tract_filing_rate <- read.csv("eviction_data/tract_level_filing_rate.csv")
# Eviction Trends
eviction_trends <- read.csv("eviction_data/trends_eviction.csv")
# Monthly Unemployment Rates
unemployment_monthly <- read_xlsx("eviction_data/unemployment_rate_montly.xlsx")
# Consumer Price Index
consumer_price_index <- read_xlsx("eviction_data/consumer_price_index_monthly.xlsx")
#Financial Health Data
financial_health <- read_xlsx("eviction_data/financial-health-of-residents-data.xlsx")
# Investigate the data set
head(tract_filings, 50)
# Import Census Tract Geometry
options(tigris_use_cache = TRUE)
# Import for Philadelphia
philadelphia_tracts <- tracts(state = "PA", county = "Philadelphia", year = 2022)
# Look at Results
plot(philadelphia_tracts$geometry)
# Make Sure Format Matches
philadelphia_tracts$GEOID <- as.character(philadelphia_tracts$GEOID)
tract_filings$id <- as.character(tract_filings$id)
# Join
evictions_geo <- philadelphia_tracts %>%
left_join(tract_filings, by = c("GEOID" = "id"))
ggplot(evictions_geo) +
geom_sf(aes(fill = month_rate), color = NA) +
scale_fill_viridis_c(option = "magma") +
labs(
title = "Eviction Rate by Census Tract",
fill = "Eviction Rate"
) +
theme_minimal()
library(sf)
library(ggplot2)
library(readr)
library(dplyr)
library(sf)
library(ggplot2)
# 1. Read CSV
hotspots <- read_csv("hotspots/philadelphia_hotspots_media_report.csv")
# 2. Convert to sf object
hotspots_sf <- st_as_sf(
hotspots,
coords = c("lon", "lat"),
crs = 4326
)
# 1. Read tract boundary
tracts <- st_read("border/Census_Blocks_2010.geojson")
# 2. Reproject hotspots to match tracts CRS
hotspots_sf <- st_transform(hotspots_sf, st_crs(tracts))
# 3. Map tracts + hotspots
ggplot() +
geom_sf(data = tracts, fill = "grey95", color = "white") +
geom_sf(
data = hotspots_sf,
aes(size = filings),
alpha = 0.7
) +
scale_size_continuous(name = "Eviction filings") +
labs(
title = "Eviction Hotspots over Census Tracts",
subtitle = "Top 100 buildings in Philadelphia",
caption = "Source: Eviction Tracking System, ACS, Census tracts"
) +
theme_minimal()
#| fig-align: "center"
#| out-width: "100px"
#| echo: false
knitr::include_graphics("trends.png")
#| fig-align: "center"
#| out-width: "100px"
#| echo: false
knitr::include_graphics("price.png")
# Data Cleaning
# Clean Financial Health Data
financial_health_clean <- financial_health
# Use row 4 as header
names(financial_health_clean) <- as.character(unlist(financial_health_clean[4, ]))
# Replace blank/NA column names with placeholders
bad_name_index <- which(is.na(names(financial_health_clean)) | names(financial_health_clean) == "")
if (length(bad_name_index) > 0) {
names(financial_health_clean)[bad_name_index] <- paste0("col_", seq_along(bad_name_index))
}
# Remove metadata rows 1–4, keep Philadelphia only
financial_health_clean <- financial_health_clean[-(1:4), ] %>%
filter(City == "Philadelphia, PA")
# Convert all but City to numeric
financial_health_numeric_columns <- setdiff(names(financial_health_clean), "City")
financial_health_clean[financial_health_numeric_columns] <-
lapply(financial_health_clean[financial_health_numeric_columns], as.numeric)
# Clean CPI Data
cpi_wide <- consumer_price_index
# Real header is row 11
names(cpi_wide) <- as.character(unlist(cpi_wide[11, ]))
cpi_wide <- cpi_wide[-(1:11), ]
cpi_wide$Year <- as.integer(as.numeric(cpi_wide$Year))
cpi_month_names <- c("Jan","Feb","Mar","Apr","May","Jun",
"Jul","Aug","Sep","Oct","Nov","Dec")
# Convert month columns to numeric
for (col in cpi_month_names) {
if (col %in% names(cpi_wide)) {
cpi_wide[[col]] <- as.numeric(cpi_wide[[col]])
}
}
# Month lookup table
month_lookup <- data.frame(
month_name = cpi_month_names,
month = 1:12
)
# Convert CPI to long format
cpi_long <- cpi_wide %>%
select(Year, all_of(cpi_month_names)) %>%
pivot_longer(cols = all_of(cpi_month_names),
names_to = "month_name",
values_to = "cpi") %>%
filter(!is.na(cpi)) %>%
left_join(month_lookup, by = "month_name") %>%
rename(year = Year)
# Clean Unemployment Data
unemployment_wide <- unemployment_monthly
# Row 10 is the real header
names(unemployment_wide) <- as.character(unlist(unemployment_wide[10, ]))
unemployment_wide <- unemployment_wide[-(1:10), ]
unemployment_wide$Year <- as.integer(as.numeric(unemployment_wide$Year))
unemployment_month_names <- c("Jan","Feb","Mar","Apr","May","Jun",
"Jul","Aug","Sep","Oct","Nov","Dec")
# Convert month columns to numeric
for (col in unemployment_month_names) {
if (col %in% names(unemployment_wide)) {
unemployment_wide[[col]] <- as.numeric(unemployment_wide[[col]])
}
}
# Convert unemployment data to long format
unemployment_long <- unemployment_wide %>%
select(Year, all_of(unemployment_month_names)) %>%
pivot_longer(cols = all_of(unemployment_month_names),
names_to = "month_name",
values_to = "unemployment_rate") %>%
filter(!is.na(unemployment_rate)) %>%
left_join(month_lookup, by = "month_name") %>%
rename(year = Year)
# Clean Monthly Eviction Trend Data
# Parse month and year
eviction_trends_clean <- eviction_trends %>%
mutate(
month_num = as.integer(substr(month, 1, 2)),
year      = as.integer(substr(month, 4, 7)),
month_date = paste0(year, "-", month_num, "-01")
)
# Merge with unemployment and CPI
eviction_trends_merged <- eviction_trends_clean %>%
left_join(unemployment_long,
by = c("year" = "year", "month_num" = "month")) %>%
left_join(cpi_long,
by = c("year" = "year", "month_num" = "month"))
# Attach Urban Institute financial variables
eviction_trends_merged <- eviction_trends_merged %>%
mutate(dummy = 1) %>%
left_join(financial_health_clean %>% mutate(dummy = 1), by = "dummy") %>%
select(-dummy)
# Add lag variables
eviction_trends_final <- eviction_trends_merged %>%
arrange(year, month_num) %>%
mutate(
l1_filings = lag(month_filings, 1),
l1_percentage_diff = lag(percentage_diff, 1)
)
# Check Financial Health
cat("Financial Health Clean")
print(str(financial_health_clean))
print(head(financial_health_clean))
# Check CPI Long Format
cat("CPI Long Format")
print(str(cpi_long))
print(head(cpi_long))
# Check Unemployment Long Format
cat("Unemployment Long Format")
print(str(unemployment_long))
print(head(unemployment_long))
# Check Eviction Data
cat("Eviction Trends Final After Macro UI Merge & Lag")
print(str(eviction_trends_final))
print(head(eviction_trends_final))
# Prepare modeling dataset
model_df <- eviction_trends_final %>%
select(
year, month_num,
month_filings,
percentage_diff,
l1_percentage_diff,
unemployment_rate,
cpi,
Overall,
`White areas`,
`Nonwhite areas`,
`% with`,
`Median amount among those with`,
`% housing-cost burdened, low-income`,
`% with home foreclosure`,
`% unbanked, metro area`,
`% received EITC, low-income`,
`Labor force participation rate`,
`% below 200% of federal poverty level`,
`Gini index of income inequality`
) %>%
filter(!is.na(percentage_diff))
eviction_model <- lm(
percentage_diff ~
l1_percentage_diff +
unemployment_rate +
cpi +
`Median amount among those with` +
`% housing-cost burdened, low-income` +
`% with home foreclosure` +
`% unbanked, metro area` +
`% received EITC, low-income` +
`Labor force participation rate` +
`% below 200% of federal poverty level` +
`Gini index of income inequality`,
data = model_df
)
summary(eviction_model)
# Model Validation: RMSE and MAE
# Extract the data actually used by the model because of UI data issues
model_used <- eviction_model$model
# Extract fitted values and residuals
predicted <- eviction_model$fitted.values
residuals <- eviction_model$residuals
# Compute MAE
mae <- mean(abs(residuals))
# Compute RMSE
rmse <- sqrt(mean(residuals^2))
# Output results
cat("Model Performance Metrics:\n")
cat("MAE  =", round(mae, 4), "\n")
cat("RMSE =", round(rmse, 4), "\n")
# Train–Test Split
# Make numeric time variables
model_df_tt <- model_df %>%
mutate(
year_num  = as.integer(year),
month_num = if ("month_num" %in% names(.)) month_num else as.integer(substr(month, 1, 2))
) %>%
arrange(year_num, month_num)
# Train–test split by time
train_df <- model_df_tt %>% filter(year_num < 2023)
test_df  <- model_df_tt %>% filter(year_num >= 2023)
# Variables used in the model
model_vars <- c(
"percentage_diff",
"l1_percentage_diff",
"unemployment_rate",
"cpi",
"Median amount among those with",
"% housing-cost burdened, low-income",
"% with home foreclosure",
"% unbanked, metro area",
"% received EITC, low-income",
"Labor force participation rate",
"% below 200% of federal poverty level",
"Gini index of income inequality"
)
# Keep only complete cases
train_df_clean <- train_df %>%
filter(if_all(all_of(model_vars), ~ !is.na(.)))
test_df_clean <- test_df %>%
filter(if_all(all_of(model_vars), ~ !is.na(.)))
# Fit Model on Training Data
eviction_model_train <- lm(
percentage_diff ~
l1_percentage_diff +
unemployment_rate +
cpi +
`Median amount among those with` +
`% housing-cost burdened, low-income` +
`% with home foreclosure` +
`% unbanked, metro area` +
`% received EITC, low-income` +
`Labor force participation rate` +
`% below 200% of federal poverty level` +
`Gini index of income inequality`,
data = train_df_clean
)
# Out-of-Sample Validation - Test Set
# Predict on test set
test_predictions <- predict(
eviction_model_train,
newdata = test_df_clean
)
# Residuals
test_residuals <- test_df_clean$percentage_diff - test_predictions
# MAE
mae_test <- mean(abs(test_residuals))
# RMSE
rmse_test <- sqrt(mean(test_residuals^2))
# Output
cat("Out-of-Sample Model Performance:\n")
cat("MAE  =", round(mae_test, 4), "\n")
cat("RMSE =", round(rmse_test, 4), "\n")
# Prepare error data for comparison
# In-sample errors
in_sample_errors <- data.frame(
residual = eviction_model$residuals,
sample_type = "In-sample"
)
# Out-of-sample errors
out_sample_errors <- data.frame(
residual = test_residuals,
sample_type = "Out-of-sample"
)
# Combine
error_compare_df <- rbind(in_sample_errors, out_sample_errors)
# Plot
ggplot(error_compare_df, aes(x = residual, fill = sample_type)) +
geom_histogram(
alpha = 0.6,
bins = 30,
position = "identity"
) +
facet_wrap(~ sample_type, scales = "free_y") +
labs(
title = "Comparison of Prediction Errors",
subtitle = "In-sample vs Out-of-sample Residual Distributions",
x = "Prediction Error (Residual)",
y = "Count"
) +
theme_minimal()
library(spdep)
# Prepare spatial neighbors from census tract geometry
nb <- poly2nb(evictions_geo)
lw <- nb2listw(nb, style = "W")
# Extract residuals from in-sample model
residuals_spatial <- evictions_geo %>%
st_drop_geometry() %>%
select(GEOID) %>%
bind_cols(residual = eviction_model$residuals)
library(spdep)
# Prepare spatial neighbors from census tract geometry
nb <- poly2nb(evictions_geo)
lw <- nb2listw(nb, style = "W")
# Extract residuals from in-sample model
residuals_spatial <- evictions_geo %>%
st_drop_geometry() %>%
select(GEOID) %>%
bind_cols(residual = eviction_model$residuals)
library(spdep)
library(spdep)
# Prepare spatial neighbors
nb <- poly2nb(evictions_geo)
lw <- nb2listw(nb, style = "W")
# Get residuals directly from model object
residuals_vec <- residual(eviction_model)
library(spdep)
# Prepare spatial neighbors
nb <- poly2nb(evictions_geo)
lw <- nb2listw(nb, style = "W")
# Get residuals directly from model object
residuals_vec <- eviction_model$residuals
# Moran's I test (handles NAs automatically)
moran_result <- moran.test(residuals_vec, lw, na.action = na.omit)
library(spdep)
# Prepare spatial neighbors from evictions_geo
nb <- poly2nb(evictions_geo)
lw <- nb2listw(nb, style = "W")
# Get residuals from model
residuals_vec <- eviction_model$residuals
# Create a dataframe with GEOID and residuals from model
model_residuals_df <- data.frame(
residual = residuals_vec
)
# Add to evictions_geo (only matching rows)
evictions_geo$model_residual <- NA
evictions_geo$model_residual[1:length(residuals_vec)] <- residuals_vec
# Remove rows with NA residuals for Moran's test
evictions_geo_clean <- evictions_geo[!is.na(evictions_geo$model_residual), ]
# Rebuild neighbor structure for clean data
nb_clean <- poly2nb(evictions_geo_clean)
lw_clean <- nb2listw(nb_clean, style = "W")
library(spdep)
# Prepare spatial neighbors from evictions_geo
nb <- poly2nb(evictions_geo, queen = TRUE)
lw <- nb2listw(nb, style = "W", zero.policy = TRUE)
# Get residuals from model
residuals_vec <- eviction_model$residuals
# Add residuals to evictions_geo
evictions_geo$model_residual <- NA
evictions_geo$model_residual[1:length(residuals_vec)] <- residuals_vec
# Moran's I test with zero.policy = TRUE
moran_result <- moran.test(evictions_geo$model_residual, lw, zero.policy = TRUE, na.action = na.omit)
# Print results
cat("Moran's I Test on Model Residuals\n")
cat("===================================\n")
cat("Moran's I statistic:", round(moran_result$statistic, 4), "\n")
cat("P-value:", round(moran_result$p.value, 4), "\n")
cat("Expected I (under null):", round(moran_result$estimate[2], 4), "\n")
